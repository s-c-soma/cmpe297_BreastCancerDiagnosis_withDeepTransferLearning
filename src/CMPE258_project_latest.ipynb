{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CMPE258_project_latest.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "B3B-qWOjJeSv",
        "-kNBqJo_VIDV",
        "zwLGQ_baVTI-",
        "cY0YH2_sS7Cv",
        "dcEM_cWytiEO"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaBkarWMpHIU"
      },
      "source": [
        "# CMPE 258 Term Project - Breast Cancer Diagnosis Using Deep Transfer Learning\n",
        "\n",
        "## Team AWS Members - Abhishek Bais, Wasae Qureshi, Subarna Chowdhury Soma \n",
        "\n",
        "## Problem Description:\n",
        "### Context  \n",
        "Invasive Ductal Carcinoma (IDC) is the most common subtype of all breast cancers. To assign an aggressiveness grade to a whole mount sample, pathologists typically focus on the regions which contain the IDC. As a result, one of the common pre-processing steps for automatic aggressiveness grading is to delineate the exact regions of IDC inside of a whole mount slide.\n",
        "\n",
        "### Content  \n",
        "The original dataset consisted of 162 whole mount slide images of Breast Cancer (BCa) specimens scanned at 40x. From that, 277,524 patches of size 50 x 50 were extracted (198,738 IDC negative and 78,786 IDC positive). Each patch’s file name is of the format: uxXyYclassC.png — > example 10253idx5x1351y1101class0.png . Where u is the patient ID (10253idx5), X is the x-coordinate of where this patch was cropped from, Y is the y-coordinate of where this patch was cropped from, and C indicates the class where 0 is non-IDC and 1 is IDC.\n",
        "\n",
        "### Acknowledgements  \n",
        "1. The original files are located here: http://gleason.case.edu/webdata/jpi-dl-tutorial/IDC_regular_ps50_idx5.zip  \n",
        "\n",
        "### Citation  \n",
        "1. https://www.ncbi.nlm.nih.gov/pubmed/27563488 \n",
        "2. http://spie.org/Publications/Proceedings/Paper/10.1117/12.2043872  \n",
        "\n",
        "### Inspiration  \n",
        "Breast cancer is the most common form of cancer in women, and invasive ductal carcinoma (IDC) is the most common form of breast cancer. Accurately identifying and categorizing breast cancer subtypes is an important clinical task, and automated methods can be used to save time and reduce error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3B-qWOjJeSv"
      },
      "source": [
        "# Check if GPU/TPU available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6MhLJuHJh2z"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SS_K1hgCcYf"
      },
      "source": [
        "# Import data read, processing libraries\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import imblearn\n",
        "import inspect\n",
        "import random\n",
        "import subprocess\n",
        "import tempfile\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from matplotlib.image import imread\n",
        "import warnings\n",
        "import tempfile\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "from numpy.random import shuffle, seed\n",
        "import itertools\n",
        "\n",
        "# Import visualization libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Import tf, keras libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D,  LSTM, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.mobilenet_v2 import preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgqVV3jJgxpZ"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdErvKZ3YsBJ"
      },
      "source": [
        "# 1.0. Data ingestion\n",
        "### Data description: \n",
        "There are a total of 555,048 patient images in the Kaggle breast cancer 'breast-histopathology-images dataset'. \n",
        "\n",
        "### These contain\n",
        "1. 397,646 images of patients with Benign/ No Cancer\n",
        "2. 157,572 images of patients with Malignant/ Have Cancer\n",
        "\n",
        "The images are obtained from the [breast cancer image dataset](https://www.kaggle.com/paultimothymooney/breast-histopathology-images) that can be found here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kNBqJo_VIDV"
      },
      "source": [
        "## 1.1. Setup for Kaggle API first use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBg-JAEKBwwB"
      },
      "source": [
        "!mkdir /root/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEyZzOhpYBlL"
      },
      "source": [
        "!mkdir /content/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2IH3U81YDH6"
      },
      "source": [
        "import json\n",
        "#token = {“username”:”YOUR-USER-NAME”,”key”:”SOME-VERY-LONG-STRING”}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob-S-nD3YJS6"
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iELGWUh1YP8W"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bpi249rYS4a"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9nASg9BpvE"
      },
      "source": [
        "!kaggle datasets list -s paultimothymooney/breast-histopathology-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6fR0NHKYmVB"
      },
      "source": [
        "## 1.2. Read in the kaggle breast cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR1Obg48Q6Nw"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images -p /kaggle/input/breast-histopathology-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8eem29wSvER"
      },
      "source": [
        "!ls /kaggle/input/breast-histopathology-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP_aNChzSkVr"
      },
      "source": [
        "# unzip\n",
        "import zipfile\n",
        "def unzip_images():\n",
        "  with zipfile.ZipFile('/kaggle/input/breast-histopathology-images/breast-histopathology-images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/kaggle/input/breast-histopathology-images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rMUCJHvZAAG"
      },
      "source": [
        "unzip_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwLGQ_baVTI-"
      },
      "source": [
        "# 2.0. Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3me0fmxLW2I0"
      },
      "source": [
        "## 2.1. Read in the breast cancer image file paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APIEt3g5WxFc"
      },
      "source": [
        "# Inspect a few unzipped images\n",
        "images  = glob('/kaggle/input/breast-histopathology-images/**/*.png', recursive=True)\n",
        "print(len(images))\n",
        "for filename in tqdm(images[0:10]):\n",
        "    print(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDa3izDVY7d"
      },
      "source": [
        "## 2.2. Create labels from patient images\n",
        "1. Benign/ No Cancer  - image files ending with class0.png\n",
        "2. Malignant/ Have Cancer - image files ending with class1.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiTksWaWVbJn"
      },
      "source": [
        "# Create labels\n",
        "#  file names ending with class0.png are of patients without cancer (benign)\n",
        "# file names ending with class1.png are of patients with cancer (malignant)\n",
        "\n",
        "benign = [] \n",
        "malignant = [] \n",
        "def create_labels(images): \n",
        "  for filename in images:\n",
        "    if filename.endswith(\"class0.png\"):\n",
        "         benign.append(filename)\n",
        "    else:\n",
        "        malignant.append(filename)\n",
        "  print(\"Benign/ No Cancer\", len(benign))\n",
        "  print(\"Malignant/ Have Cancer\", len(malignant))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRcbhtlVpMR"
      },
      "source": [
        "create_labels(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiAvkLO3VgNr"
      },
      "source": [
        "## 2.3. Inspect the benign, malignant class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-H-721XU2__"
      },
      "source": [
        "# inspect the class distribution\n",
        "df_benign = pd.DataFrame(benign, columns=['image'])\n",
        "df_malignant = pd.DataFrame(malignant, columns=['image'])\n",
        "df_benign['label'] = 0\n",
        "df_malignant['label'] = 1\n",
        "print(\"Benign/ No Cancer images sample\", df_benign.shape)\n",
        "print(\"Malignant/ Have Cancer\", df_malignant.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUgwirQ7VkQb"
      },
      "source": [
        "## 2.4. Report the class distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL2fdtLhVKSM"
      },
      "source": [
        "# Report the distribution of benign vs malignant images\n",
        "df_data = pd.concat([df_benign, df_malignant], axis=0).reset_index(drop=True)\n",
        "plt.figure(figsize=(15,5), edgecolor='b')\n",
        "df_data['label'].value_counts().plot(kind=\"barh\", color='peru')\n",
        "plt.title('Benign vs Malignant image distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQgIbknyVwKD"
      },
      "source": [
        "## 2.5. Resolve class imbalance by random downsampling majority class\n",
        "### Pick 5000 images to avoid memory overhead of loading images\n",
        "a. 2500 benign images  \n",
        "b. 2500 malignant images  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwVMssXXVxHx"
      },
      "source": [
        "# Random downsample majority class, here benign to (total = ~150000)\n",
        "sample_size = 2500\n",
        "df_benign = df_benign.sample(sample_size, random_state=101)\n",
        "df_malignant = df_malignant.sample(sample_size, random_state=101)\n",
        "\n",
        "# concatenate the benign with malignant patient images\n",
        "df_data = pd.concat([df_benign, df_malignant], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Report the benign vs malignant class distributions\n",
        "df_data['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOro2u5IV-Qe"
      },
      "source": [
        "## 2.6. Inspect the class distributions after balancing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQEyL9LIV_Ut"
      },
      "source": [
        "# Report the distribution of benign vs malignant images\n",
        "df_data = pd.concat([df_benign, df_malignant], axis=0).reset_index(drop=True)\n",
        "plt.figure(figsize=(15,5), edgecolor='b')\n",
        "df_data['label'].value_counts().plot(kind=\"barh\", color='peru')\n",
        "plt.title('Benign vs Malignant image distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObGjoao9a5V8"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEYZggcDdkSj"
      },
      "source": [
        "## 2.7. Load images from file paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xVuBEJiTh1L"
      },
      "source": [
        "# Resize images to 224, 224 to be compatible with pre-trained CNN models\n",
        "def create_image_arrays(df, label):\n",
        "  images_array = []\n",
        "  for i in range(len(df)) :\n",
        "    i = df.iloc[i].image\n",
        "    if i.endswith('.png'):\n",
        "      image = cv2.imread(i, cv2.IMREAD_COLOR)\n",
        "      image_resized = cv2.resize(image, (224, 224), interpolation=cv2.INTER_LINEAR) \n",
        "      images_array.append([image_resized, label])\n",
        "  return images_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3nHwDSiTl9M"
      },
      "source": [
        "benign_images_array = create_image_arrays(df_benign, 0)\n",
        "malignant_images_array = create_image_arrays(df_malignant, 1)\n",
        "all_images = np.concatenate((benign_images_array, malignant_images_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbIVKFY_XRQH"
      },
      "source": [
        "print(all_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUSu0pkMXVAT"
      },
      "source": [
        "## 2.8. Normalize, Reshape image to 224, 224, 3 for different pre-trained CNN models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNm2MjzDVC8e"
      },
      "source": [
        "# Reshape all images\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in all_images:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "print(len(X))\n",
        "print(len(y))\n",
        "\n",
        "X = np.array(X).reshape(-1, 224, 224, 3)\n",
        "X = X/255.0\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmoh9dfupu-a"
      },
      "source": [
        "## 2.9. Create train, validation, test splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUr1EH9QhxeE"
      },
      "source": [
        "### 2.9.1. Create 80/20 train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPsziKnggXPN"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XambioZIibQz"
      },
      "source": [
        "### 2.9.2. Create 75/25 train/val split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Ie2XJVgj9v"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUPomDloiinH"
      },
      "source": [
        "### 2.9.3. 1-hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9uZ4YA_gusm"
      },
      "source": [
        "y_train = to_categorical(Y_train, num_classes = 2)\n",
        "y_val = to_categorical(Y_val, num_classes = 2)\n",
        "y_test = to_categorical(Y_test, num_classes = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3C5WvnYimzZ"
      },
      "source": [
        "### 2.9.4. Examine input shapes for train, val, test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZTQFP-PhIA7"
      },
      "source": [
        "# print shapes of image samples in train, val, test\n",
        "print(\"Shape of training images\", X_train.shape)\n",
        "print(\"Shape of validation images\", X_val.shape)\n",
        "print(\"Shape of test images\", X_test.shape)\n",
        "\n",
        "print(\"Shape of training labels\", y_train.shape)\n",
        "print(\"Shape of validation labels\", y_val.shape)\n",
        "print(\"Shape of test labels\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY0YH2_sS7Cv"
      },
      "source": [
        "# 3.0. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N-feaneVUB1"
      },
      "source": [
        "# View the data\n",
        "def visualize_N_elems_of_dataset(X, y, row, col, name):\n",
        "  print(\"Visualizing the \" + name + \" dataset.\")\n",
        "  fig = plt.figure(figsize=(15,10))\n",
        "\n",
        "  # Plot row * col images of the dataset\n",
        "  for image in range(1, col*row+1):\n",
        "    ax = fig.add_subplot(row, col, image)\n",
        "    if y[image] == 1:\n",
        "        ax.title.set_text('Benign')\n",
        "    else:\n",
        "        ax.title.set_text('Malignant')\n",
        "    ax.imshow(X[image], cmap='Accent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbVFzj4U0mpW"
      },
      "source": [
        "## 3.1. View some images from training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjXZ2IXFTNqb"
      },
      "source": [
        "# Explore some benign, malignant cancer patient images from training data\n",
        "row = 2\n",
        "col = 4\n",
        "visualize_N_elems_of_dataset(X_train, Y_train, row, col, \"train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G9mmZaJjNvg"
      },
      "source": [
        "## 3.2. View some images from validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqOwp2GAjBpP"
      },
      "source": [
        "# Explore some benign, malignant cancer patient images from validation data\n",
        "row = 2\n",
        "col = 4\n",
        "visualize_N_elems_of_dataset(X_val, Y_val, row, col, \"validation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQKD23W80uxe"
      },
      "source": [
        "## 3.3 View some images from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATuo-dfATNXx"
      },
      "source": [
        "# Explore some benign, malignant cancer patient images from test data\n",
        "row = 2\n",
        "col = 4\n",
        "visualize_N_elems_of_dataset(X_test, Y_test, row, col, \"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7d-dC5FcZ2"
      },
      "source": [
        "# 4.0. Configure for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjZPCs6_GEEU"
      },
      "source": [
        "## 4.1. Get pre-trained CNN models to evaluate\n",
        "1. DenseNet201\n",
        "2. InceptionResNetV2\n",
        "3. NASNetMobile\n",
        "4. ResNet50V2\n",
        "5. ResNet152V2\n",
        "6. VGG16\n",
        "\n",
        "These will be evaluated against various metrics, best picked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0M1pwxTJ8fZ"
      },
      "source": [
        "# inspect available pre-trained models in keras\n",
        "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}\n",
        "for name, model in tqdm(model_dictionary.items()):\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQTWb-Kk-qjM"
      },
      "source": [
        "# check if model in models of interest\n",
        "def models_to_evaluate_contains(name):\n",
        "  contains = False\n",
        "  if ((\"ResNet50V2\" == name) or (\"ResNet152V2\" == name) or (\"NASNetMobile\" == name) or \n",
        "      (\"VGG16\" == name) or (\"InceptionResNetV2\" == name) or (\"DenseNet201\" == name) or (\"Xception\" == name)):\n",
        "    contains = True\n",
        "  return contains\n",
        "\n",
        "# get pre-trained cnn feature models of interest\n",
        "model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}\n",
        "my_pretrained_cnn_feature_models = {}\n",
        "for name, model in tqdm(model_dictionary.items()):\n",
        "  if models_to_evaluate_contains(name):\n",
        "    my_pretrained_cnn_feature_models[name] = model\n",
        "\n",
        "# print interesting models found to evaluate\n",
        "for name, model in my_pretrained_cnn_feature_models.items():\n",
        "  print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akxXiU69L3JS"
      },
      "source": [
        "## 4.2. Setup base hyper-parameters for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZi14S6-LqkT"
      },
      "source": [
        "# Set hyperparameters settings\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "num_iterations = len(X_train/batch_size)\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "num_channels = 3 #rgb\n",
        "optimizer = 'rmsprop'\n",
        "patience = 20\n",
        "verbose = 1\n",
        "factor = 0.2\n",
        "min_lr = 0.0001\n",
        "augment_images = False\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "monitor = 'val_loss'\n",
        "\n",
        "# Set custom metrics to monitor\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),  \n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "]\n",
        "\n",
        "# Set adaptive learing rate setting\n",
        "adaptive_lr = ReduceLROnPlateau(monitor=monitor, \n",
        "                                patience=patience, \n",
        "                                verbose=verbose, \n",
        "                                factor=factor, \n",
        "                                min_lr=min_lr)\n",
        "\n",
        "# Set model check-pointing settings\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "# Set early stop settings\n",
        "es = EarlyStopping(verbose=verbose, patience=patience)\n",
        "\n",
        "# Set tensorboard callbacks for log visualization\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6jwYEGnTEjb"
      },
      "source": [
        "## 4.3. Setup on demand image augmentation\n",
        "### Use customizable hyper-params\n",
        "a. featurewise_center=False,  # set input mean to 0 over the dataset  \n",
        "b. samplewise_center=False,  # set each sample mean to 0  \n",
        "c. featurewise_std_normalization=False,  # divide inputs by std of the dataset  \n",
        "d. samplewise_std_normalization=False,  # divide each input by its std  \n",
        "e. zca_whitening=False,  # apply ZCA whitening  \n",
        "f. rotation_range=10,  # rotate images in the range (degrees, 0 to 180)  \n",
        "g. zoom_range = 0.1, # Randomly zoom image   \n",
        "h. width_shift_range=0.1,  # randomly shift images horizontally  \n",
        "i. height_shift_range=0.1,  # randomly shift images vertically  \n",
        "j. horizontal_flip=True,  # randomly flip images  \n",
        "k. vertical_flip=True)  # randomly flip images  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k68WfD47X1Cu"
      },
      "source": [
        "# Set hyper params for image augmentation\n",
        "featurewise_center=False \n",
        "samplewise_center=False \n",
        "featurewise_std_normalization=False \n",
        "samplewise_std_normalization=False \n",
        "zca_whitening=False \n",
        "rotation_range=20 \n",
        "zoom_range = [1.0,1.2] \n",
        "width_shift_range=0.0\n",
        "height_shift_range=0.0\n",
        "horizontal_flip=True \n",
        "vertical_flip=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jalTMF8kOodH"
      },
      "source": [
        "# Configure Image Data Generator\n",
        "def get_augmented_images():\n",
        "  gen = ImageDataGenerator(\n",
        "        rotation_range = rotation_range,\n",
        "        zoom_range = zoom_range,\n",
        "        horizontal_flip = horizontal_flip,\n",
        "        vertical_flip = vertical_flip)\n",
        "  return gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lHNJeZTPqg"
      },
      "source": [
        "## 4.4. Build hybrid CNN + DNN classification model\n",
        "\n",
        "### 1. Use pre-trained CNN model \n",
        "#### When used as a feature extractor  \n",
        "a. Freeze weights of pre-trained CNN model  \n",
        "b. Freeze layers of pre-trained CNN model  \n",
        "\n",
        "### 2. Add custom layers   \n",
        "a. Dense  \n",
        "b. Dropout    - 0.2  \n",
        "c. BatchNormalization  \n",
        "\n",
        "### Note:\n",
        "a. We added BatchNormalization layer based on reading from this [paper](https://ui.adsabs.harvard.edu/abs/2016arXiv161201452S/abstract) which showed better results for pre-trained CNN with batch normalization vs without.  \n",
        "\n",
        "b. We experimented with and without BatchNormalization layer and observed BatchNormalization to outperform vs without BatchNormalization.  \n",
        "\n",
        "### 3. Add DNN/RNN layer to classify  \n",
        "a. Loss       - Binary cross entropy  \n",
        "b. Optimizer  - rmsProp/sgd/adam  \n",
        "c. Activation - softmax/sigmoid  \n",
        "\n",
        "### 4. Use customizable hyper-params\n",
        "a. batch_size  \n",
        "b. num_epochs  \n",
        "c. num_iterations = len(X_train/batch_size)  \n",
        "d. patience  \n",
        "e. adaptive lr  \n",
        "f. model check pointing  \n",
        "g. augment_images  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZyApEz49odM"
      },
      "source": [
        "from keras.layers import Lambda, Reshape\n",
        "# train and evaluate pre-trained CNN models \n",
        "def train_evaluate_classifiers(X_train, y_train, X_test, y_test, \n",
        "                               augment_images, \n",
        "                               add_batch_normalization,\n",
        "                               fine_tune_pre_trained_cnn_model):\n",
        "  eval_metrics = {'model_name': [], \n",
        "                  'model_params': [], \n",
        "                  'history': [],\n",
        "                  'training_accuracy': [],\n",
        "                  'val_accuracy': [],\n",
        "                  'model' : []\n",
        "                  }\n",
        "\n",
        "   # perform image augmentation if requested\n",
        "  if (augment_images):\n",
        "    train_gen = get_augmented_images()\n",
        "    train_gen.fit(X_train)\n",
        "    test_gen = get_augmented_images()\n",
        "    test_gen.fit(X_test)\n",
        "    \n",
        "  # do a muller loop on the models\n",
        "  for name, model in my_pretrained_cnn_feature_models.items():\n",
        "    print('\\n------- Begin Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "\n",
        "    # set input shape\n",
        "    input_shape=(image_height, image_width, num_channels)\n",
        "    \n",
        "    # get pre-trained cnn feature model with max pool\n",
        "    pre_trained_cnn_feature_model = model(include_top=False, \n",
        "                                    pooling='max', \n",
        "                                    input_shape=input_shape)\n",
        "\n",
        "    # if fine tune pre-trained cnn model, set, last layer trainable\n",
        "    if (fine_tune_pre_trained_cnn_model):\n",
        "       # freeze weights of pre-trained cnn feature model\n",
        "       pre_trained_cnn_feature_model.trainable = True\n",
        "\n",
        "       # freeze all layers before layer 15, i.e make last 4 layers trainable\n",
        "       for layer in pre_trained_cnn_feature_model.layers[:15]:\n",
        "          layer.trainable = False\n",
        "    else:\n",
        "       # freeze weights of pre-trained cnn feature model\n",
        "       pre_trained_cnn_feature_model.trainable = False\n",
        "\n",
        "       # freeze layers of pre-trained cnn feature model\n",
        "       for layer in pre_trained_cnn_feature_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # add custom layers over pre-trained model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(pre_trained_cnn_feature_model)\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    # add batch normalization on demand\n",
        "    if (add_batch_normalization):\n",
        "      model.add(layers.BatchNormalization())\n",
        "       \n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  metrics=METRICS, \n",
        "                  optimizer=optimizer)\n",
        "    # fit\n",
        "    if (augment_images):\n",
        "      history=model.fit(x = train_gen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data = test_gen.flow(X_test, y_test),\n",
        "                        verbose = 1, epochs = num_epochs,\n",
        "                        callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "    else:\n",
        "      history=model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                        validation_data = (X_test, y_test),\n",
        "                        verbose = 1, epochs = num_epochs,\n",
        "                        callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "\n",
        "    # calculate all relevant metrics\n",
        "    eval_metrics['model_name'].append(name)\n",
        "    eval_metrics['model_params'].append(pre_trained_cnn_feature_model.count_params())\n",
        "    eval_metrics['history'].append(history)\n",
        "    eval_metrics['training_accuracy'].append(history.history['accuracy'][-1])\n",
        "    eval_metrics['val_accuracy'].append(history.history['val_accuracy'][-1])\n",
        "    eval_metrics['model'].append(model)\n",
        "\n",
        "    print('\\n------- End Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "  return eval_metrics "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WS0mQaJxYS-"
      },
      "source": [
        "## 4.5. Fine tune hyper-parameters and evaluate best CNN + DNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCy-Mu9hgINS"
      },
      "source": [
        "# fine tune and evaluate best pre-trained CNN models with DNN classifer\n",
        "def hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                 augment_images,\n",
        "                                                 add_batch_normalization,\n",
        "                                                 dropout_rate,\n",
        "                                                 optimizer,\n",
        "                                                 num_epochs,\n",
        "                                                 fine_tune_pre_trained_cnn_model):\n",
        "  eval_metrics = {'model_name': [], \n",
        "                  'model_params': [], \n",
        "                  'history': [],\n",
        "                  'training_accuracy': [],\n",
        "                  'val_accuracy': [],\n",
        "                  'model' : []\n",
        "                  }\n",
        "\n",
        "  pretrained_cnn_feature_models = {}\n",
        "  model_dictionary = {m[0]:m[1] for m in inspect.getmembers(tf.keras.applications, inspect.isfunction)}\n",
        "  for name, model in tqdm(model_dictionary.items()):\n",
        "     if (\"VGG16\" == name):\n",
        "      pretrained_cnn_feature_models[name] = model\n",
        "      break\n",
        "\n",
        "  # perform image augmentation if requested\n",
        "  if (augment_images):\n",
        "    train_gen = get_augmented_images()\n",
        "    train_gen.fit(X_train)\n",
        "    test_gen = get_augmented_images()\n",
        "    test_gen.fit(X_test)\n",
        "    \n",
        "  # do a muller loop on the models\n",
        "  for name, model in pretrained_cnn_feature_models.items():\n",
        "    print('\\n------- Begin Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "\n",
        "    # set input shape\n",
        "    input_shape=(image_height, image_width, num_channels)\n",
        "    \n",
        "    # get pre-trained cnn feature model with max pool\n",
        "    pre_trained_cnn_feature_model = model(include_top=False, \n",
        "                                    pooling='max', \n",
        "                                    input_shape=input_shape)\n",
        "\n",
        "    # if fine tune pre-trained cnn model, set, last layer trainable\n",
        "    if (fine_tune_pre_trained_cnn_model):\n",
        "       # freeze weights of pre-trained cnn feature model\n",
        "       pre_trained_cnn_feature_model.trainable = True\n",
        "\n",
        "       # freeze all layers before layer 15, i.e make last 4 layers trainable\n",
        "       for layer in pre_trained_cnn_feature_model.layers[:15]:\n",
        "          layer.trainable = False\n",
        "    else:\n",
        "       # freeze weights of pre-trained cnn feature model\n",
        "       pre_trained_cnn_feature_model.trainable = False\n",
        "\n",
        "       # freeze layers of pre-trained cnn feature model\n",
        "       for layer in pre_trained_cnn_feature_model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # Make sure you have frozen the correct layers\n",
        "    for i, layer in enumerate(pre_trained_cnn_feature_model.layers):\n",
        "      print(i, layer.name, layer.trainable)\n",
        "\n",
        "    # add custom layers over pre-trained model\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(pre_trained_cnn_feature_model)\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    # add batch normalization on demand\n",
        "    if (add_batch_normalization):\n",
        "      model.add(layers.BatchNormalization())\n",
        "    \n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='binary_crossentropy', \n",
        "                  metrics=METRICS, \n",
        "                  optimizer=optimizer)\n",
        "     \n",
        "    # fit\n",
        "    if (augment_images):\n",
        "      history=model.fit(x = train_gen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                        validation_data = test_gen.flow(X_test, y_test),\n",
        "                        verbose = 1, epochs = num_epochs,\n",
        "                        callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "    else:\n",
        "      history=model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                        validation_data = (X_test, y_test),\n",
        "                        verbose = 1, epochs = num_epochs,\n",
        "                        callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "\n",
        "    # calculate all relevant metrics\n",
        "    eval_metrics['model_name'].append(name)\n",
        "    eval_metrics['model_params'].append(pre_trained_cnn_feature_model.count_params())\n",
        "    eval_metrics['history'].append(history)\n",
        "    eval_metrics['training_accuracy'].append(history.history['accuracy'][-1])\n",
        "    eval_metrics['val_accuracy'].append(history.history['val_accuracy'][-1])\n",
        "    eval_metrics['model'].append(model)\n",
        "\n",
        "    print('\\n------- End Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "  return eval_metrics "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQESN4x8aBiR"
      },
      "source": [
        "## 4.6. Fine tune hyper-parameters and evaluate best CNN + LSTM classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhzLxJp9UIe"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "\n",
        "# fine tune and evaluate best pre-trained CNN models with DNN classifer\n",
        "def hyper_param_tune_evaluate_best_RNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                 augment_images,\n",
        "                                                 add_batch_normalization,\n",
        "                                                 dropout_rate,\n",
        "                                                 optimizer,\n",
        "                                                 num_epochs,\n",
        "                                                 num_embeddings,\n",
        "                                                 lstm_units,\n",
        "                                                 add_dropout,\n",
        "                                                 fine_tune_pre_trained_cnn_model):\n",
        "  eval_metrics = {'model_name': [], \n",
        "                  'model_params': [], \n",
        "                  'history': [],\n",
        "                  'training_accuracy': [],\n",
        "                  'val_accuracy': [],\n",
        "                  'model' : []\n",
        "                  }\n",
        "\n",
        "  # perform image augmentation if requested\n",
        "  if (augment_images):\n",
        "    train_gen = get_augmented_images()\n",
        "    train_gen.fit(X_train)\n",
        "    test_gen = get_augmented_images()\n",
        "    test_gen.fit(X_test)\n",
        "    \n",
        "  # do a muller loop on the models\n",
        "  name = 'VGG16'\n",
        "  print('\\n------- Begin Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "\n",
        "  # set input shape\n",
        "  input_shape=(image_height, image_width, num_channels)\n",
        "\n",
        "  pre_trained_cnn_feature_model = VGG16(include_top=False, \n",
        "                                       input_shape=input_shape, \n",
        "                                       weights=\"imagenet\") \n",
        "\n",
        "  # if fine tune pre-trained cnn model, set, last layer trainable\n",
        "  if (fine_tune_pre_trained_cnn_model):\n",
        "    # freeze weights of pre-trained cnn feature model\n",
        "    pre_trained_cnn_feature_model.trainable = True\n",
        "\n",
        "    # freeze all layers before layer 15, i.e make last 4 layers trainable\n",
        "    for layer in pre_trained_cnn_feature_model.layers[:15]:\n",
        "      layer.trainable = False\n",
        "  else:\n",
        "    # freeze weights of pre-trained cnn feature model\n",
        "    pre_trained_cnn_feature_model.trainable = False\n",
        "\n",
        "    # freeze layers of pre-trained cnn feature model\n",
        "    for layer in pre_trained_cnn_feature_model.layers:\n",
        "      layer.trainable = False\n",
        "    \n",
        "  # Make sure you have frozen the correct layers\n",
        "  for i, layer in enumerate(pre_trained_cnn_feature_model.layers):\n",
        "    print(i, layer.name, layer.trainable)\n",
        "\n",
        "  # Get CNN features\n",
        "  features = GlobalAveragePooling2D()(pre_trained_cnn_feature_model.output)\n",
        "\n",
        "  # Add embeddings, LSTM on top \n",
        "  embed_layer = Embedding(num_embeddings, lstm_units, mask_zero=True)(features)\n",
        "  lstm_layer = LSTM(lstm_units)(embed_layer)\n",
        "\n",
        "  # Add custom layers\n",
        "  hidden_layer = Dense(512, activation=\"relu\")(lstm_layer)\n",
        "  if (add_dropout):\n",
        "    hidden_layer = Dropout(dropout_rate)(hidden_layer)\n",
        "  hidden_layer = Dense(128, activation=\"relu\")(hidden_layer)\n",
        "\n",
        "  if (add_dropout):\n",
        "    hidden_layer = Dropout(dropout_rate)(hidden_layer)\n",
        "\n",
        "  if (add_batch_normalization):\n",
        "    hidden_layer = BatchNormalization() (hidden_layer)\n",
        "  \n",
        "  outputs = Dense(2, activation=\"softmax\")(hidden_layer)\n",
        "  model = Model([pre_trained_cnn_feature_model.input], outputs)\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "                metrics=METRICS, \n",
        "                optimizer=optimizer)\n",
        "  model.summary()\n",
        "     \n",
        "  # fit\n",
        "  if (augment_images):\n",
        "    history=model.fit(x = train_gen.flow(X_train, y_train, batch_size=batch_size),\n",
        "                     validation_data = test_gen.flow(X_test, y_test),\n",
        "                     verbose = 1, epochs = num_epochs,\n",
        "                     callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "  else:\n",
        "    history=model.fit(X_train, y_train, batch_size=batch_size,\n",
        "                      validation_data = (X_test, y_test),\n",
        "                      verbose = 1, epochs = num_epochs,\n",
        "                      callbacks=[adaptive_lr, mcp, es, tensorboard_callback])\n",
        "\n",
        "  # calculate all relevant metrics\n",
        "  eval_metrics['model_name'].append(name)\n",
        "  eval_metrics['model_params'].append(pre_trained_cnn_feature_model.count_params())\n",
        "  eval_metrics['history'].append(history)\n",
        "  eval_metrics['training_accuracy'].append(history.history['accuracy'][-1])\n",
        "  eval_metrics['val_accuracy'].append(history.history['val_accuracy'][-1])\n",
        "  eval_metrics['model'].append(model)\n",
        "\n",
        "  print('\\n------- End Training Model = %s for %.2f epochs --------' %(name, num_epochs))\n",
        "  model.summary()\n",
        "  return eval_metrics "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0ie898tObEG"
      },
      "source": [
        "## 4.7. Setup model for training with CNN + custom layers + DNN layers¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79OQH7ayNNbH"
      },
      "source": [
        "# Train the different models\n",
        "def train_model(augment_images, add_batch_normalization, fine_tune_pre_trained_cnn_model):\n",
        "  warnings.filterwarnings('ignore')\n",
        "  eval_metrics = train_evaluate_classifiers(X_train, y_train, X_val, y_val, \n",
        "                                            augment_images,\n",
        "                                            add_batch_normalization,\n",
        "                                            fine_tune_pre_trained_cnn_model)\n",
        "  return eval_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcEM_cWytiEO"
      },
      "source": [
        "# 5.0. Visualization Helpers for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G73nS64vyb7S"
      },
      "source": [
        "## 5.1. Helper - Visualize models by accuracy of prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nBB6FKiCSG6"
      },
      "source": [
        "# Plot accuracy results\n",
        "def visualize_accuracy_results(metrics):\n",
        "  print('----- Displaying Models by accuracy of prediction -----')\n",
        "  fig, ax = plt.subplots(ncols=7, figsize=(35,5))\n",
        "  \n",
        "  # Columns = model_name\tmodel_params\thistory\ttest_accuracy\tmodel\n",
        "  for i, row in metrics.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    history = row['history']\n",
        "    ax[i].set_title(model_name)\n",
        "    ax[i].plot(history.history[\"accuracy\"], 'b', label=\"training accuracy\")\n",
        "    ax[i].plot(history.history[\"val_accuracy\"], 'r', label=\"validation vccuracy\")\n",
        "    ax[i].legend(loc=\"best\")\n",
        "    ax[i].grid()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ6ADp-4p1zb"
      },
      "source": [
        "## 5.2. Helper - Visualize models by size =(model params)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWKdNP_Zcjo"
      },
      "source": [
        "# Report results\n",
        "def visualize_models_by_size(metrics):\n",
        "  print('----- Displaying Models by size=(model params) -----')\n",
        "  metrics.sort_values('model_params', inplace=True) \n",
        "  display(metrics[['model_name', 'model_params', 'training_accuracy', 'val_accuracy']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly7J06NJZr6g"
      },
      "source": [
        "## 5.3. Helper - Visualize models by accuracy of prediction vs size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw2ckRE0Zq8v"
      },
      "source": [
        "# Visualize accuracy of different models\n",
        "def visualize_accuracy_vs_size(metrics):\n",
        "  print('----- Displaying Models by accuracy vs size -----')\n",
        "  markers=[\".\",\",\",\"o\",\"v\",\"^\",\"<\",\">\",\"1\",\"2\",\"3\",\"4\",\"8\",\"s\",\"p\",\"P\",\"*\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\",4,5,6,7,8,9,10,11]\n",
        "\n",
        "  # Plot metrics\n",
        "  plt.figure(figsize=(10,8))\n",
        "  for model in metrics.itertuples():\n",
        "    plt.scatter(model.model_params, model.val_accuracy, \n",
        "                label=model.model_name, marker=markers[model.Index], \n",
        "                s=150, linewidths=2)\n",
        "  plt.xscale('log')\n",
        "  plt.xlabel('Total Parameters in Model')\n",
        "  plt.ylabel('Validation Accuracy with 25 epochs')\n",
        "  plt.ylabel('Validation Accuracy with %s epochs' %(num_epochs))\n",
        "  plt.title('Accuracy vs Model Params')\n",
        "  plt.legend(bbox_to_anchor=(1, 1), loc='upper left'); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHYe1eihzmV3"
      },
      "source": [
        "## 5.4. Helper - Visualize models by loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZQCi-38zSAF"
      },
      "source": [
        "# Plot loss results\n",
        "def visualize_loss_results(metrics):\n",
        "  print('----- Displaying Models by loss -----')\n",
        "  fig, ax = plt.subplots(ncols=7, figsize=(35,5))\n",
        "\n",
        "  # Columns = model_name\tmodel_params\thistory\ttest_accuracy\tmodel\n",
        "  for i, row in metrics.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    history = row['history']\n",
        "    ax[i].set_title(model_name)\n",
        "    ax[i].plot(history.history[\"loss\"], 'b', label=\"training loss\")\n",
        "    ax[i].plot(history.history[\"val_loss\"], 'r', label=\"validation loss\")\n",
        "    ax[i].legend(loc=\"best\")\n",
        "    ax[i].grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEGLsiton6kg"
      },
      "source": [
        "## 5.5. Helper - Visualize models by AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75OlzP5Hnyt3"
      },
      "source": [
        "# Plot auc results\n",
        "def visualize_auc_results(metrics):\n",
        "  print('----- Displaying Models by auc -----')\n",
        "  fig, ax = plt.subplots(ncols=7, figsize=(35,5))\n",
        "\n",
        "  # Columns = model_name\tmodel_params\thistory\ttest_accuracy\tmodel\n",
        "  for i, row in metrics.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    history = row['history']\n",
        "    ax[i].set_title(model_name)\n",
        "    ax[i].plot(history.history[\"auc\"], 'b', label=\"AUC\")\n",
        "    ax[i].legend(loc=\"best\")\n",
        "    ax[i].grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LpHdpAToNBw"
      },
      "source": [
        "## 5.6. Helper - Visualize models by precision "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PdpwvL-od9G"
      },
      "source": [
        "# Plot auc results\n",
        "def visualize_precision_results(metrics):\n",
        "  print('----- Displaying Models by precision -----')\n",
        "  fig, ax = plt.subplots(ncols=7, figsize=(35,5))\n",
        "\n",
        "  # Columns = model_name\tmodel_params\thistory\ttest_accuracy\tmodel\n",
        "  for i, row in metrics.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    history = row['history']\n",
        "    ax[i].set_title(model_name)\n",
        "    ax[i].plot(history.history[\"precision\"], 'b', label=\"Training Precision\")\n",
        "    ax[i].plot(history.history[\"val_precision\"], 'r', label=\"Validation Precision\")\n",
        "    ax[i].legend(loc=\"best\")\n",
        "    ax[i].grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2SKmuQVpTpB"
      },
      "source": [
        "## 5.7. Helper - Visualize models by recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCXbuKLKpaDO"
      },
      "source": [
        "# Plot auc results\n",
        "def visualize_recall_results(metrics):\n",
        "  print('----- Displaying Models by recall -----')\n",
        "  fig, ax = plt.subplots(ncols=7, figsize=(35,5))\n",
        "\n",
        "  # Columns = model_name\tmodel_params\thistory\ttest_accuracy\tmodel\n",
        "  for i, row in metrics.iterrows():\n",
        "    model_name = row['model_name']\n",
        "    history = row['history']\n",
        "    ax[i].set_title(model_name)\n",
        "    ax[i].plot(history.history[\"recall\"], 'b', label=\"Training Recall\")\n",
        "    ax[i].plot(history.history[\"val_recall\"], 'r', label=\"Validation Recall\")\n",
        "    ax[i].legend(loc=\"best\")\n",
        "    ax[i].grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PEo58PJz3ix"
      },
      "source": [
        "## 5.8. Helper - Visualize best model summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEgbRd1sz2o0"
      },
      "source": [
        "# Report summary of best model\n",
        "def visualize_best_model_summary(metrics):\n",
        "  print('----- Displaying Best Model summary -----')\n",
        "  best_model = 0\n",
        "  metrics.sort_values(by='val_accuracy', ascending=False, inplace=True)\n",
        "  best_model_test_accuracy = metrics.iloc[0]['val_accuracy']\n",
        "\n",
        "  # get the best model, report summary\n",
        "  for model in metrics.itertuples():\n",
        "    if model.val_accuracy == best_model_test_accuracy:\n",
        "      best_model = model.model\n",
        "      print('Best model for breast cancer image classification is %s with validation accuracy of %0.02f percent.' %(model.model_name, model.val_accuracy*100))\n",
        "      \n",
        "      # report best model summary\n",
        "      best_model.summary()\n",
        "      break\n",
        "\n",
        "  return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a47zQ1_o0LRf"
      },
      "source": [
        "## 5.9. Helper - Visualize best model classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmg7L-UF0QwJ"
      },
      "source": [
        "# Visualize classification report\n",
        "def visualize_best_model_classification_report(model):\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_predicted = np.argmax(y_pred, axis=1)\n",
        "  y_expected = np.argmax(y_test, axis=1)\n",
        "  report = classification_report(y_true=y_expected, y_pred=y_predicted, target_names=['negative', 'positive'])\n",
        "  print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW-5U_Fw0RRc"
      },
      "source": [
        "## 5.10. Helper - Visualize best model confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL__92zH4ujW"
      },
      "source": [
        "# plot confusion matrics\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=55)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcIjwlI54Al_"
      },
      "source": [
        "# Visualize confusion matrix\n",
        "def visualize_best_model_confusion_matrix(model):\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_predicted = np.argmax(y_pred, axis=1)\n",
        "  y_expected = np.argmax(y_test, axis=1)\n",
        "  cm = confusion_matrix(y_expected, y_predicted)\n",
        "  cm_plot_label =['Benign', 'Malignant']\n",
        "  plot_confusion_matrix(cm, cm_plot_label, title ='Confusion Matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YL73_vC0tWG"
      },
      "source": [
        "## 5.11. Helper - Visualize best model top common errors in prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI1kY3ku7qug"
      },
      "source": [
        "# visualize top commonprediction errors\n",
        "def visualize_best_model_top_common_errors(model):\n",
        "  y_pred = best_model_CNN_with_DNN.predict(X_test)\n",
        "  y_predicted = np.argmax(y_pred, axis=1)\n",
        "  y_expected = np.argmax(y_test, axis=1)\n",
        "  i=0\n",
        "  prop_class=[]\n",
        "  mis_class=[]\n",
        "\n",
        "  for i in range(len(Y_test)):\n",
        "      if(y_expected[i] != y_predicted[i]):\n",
        "            prop_class.append(i)\n",
        "      if(len(prop_class)==8):\n",
        "            break\n",
        "        \n",
        "  i=0\n",
        "  for i in range(len(Y_test)):\n",
        "      if(not y_expected[i]== y_predicted[i]):\n",
        "          mis_class.append(i)\n",
        "      if(len(mis_class)==8):\n",
        "          break\n",
        "\n",
        "  # # Display first 8 images of benign\n",
        "  w=60\n",
        "  h=40\n",
        "  fig=plt.figure(figsize=(18, 10))\n",
        "  columns = 4\n",
        "  rows = 2\n",
        "\n",
        "  def Transfername(namecode):\n",
        "      if namecode==1:\n",
        "          return \"Malignant\"\n",
        "      else:\n",
        "          return \"Benign\"\n",
        "      \n",
        "  for i in range(len(prop_class)):\n",
        "      ax = fig.add_subplot(rows, columns, i+1)\n",
        "      ax.set_title(\"Predicted result:\"+ Transfername(y_predicted[prop_class[i]])\n",
        "                        +\"\\n\"+\"Actual result: \"+ Transfername(y_expected[prop_class[i]]))\n",
        "      plt.imshow(X_test[prop_class[i]], interpolation='nearest')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhrWTaIPyzj2"
      },
      "source": [
        "# 6.0. Train and Evaluate multiple CNN + custom layers + DNN classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ylAFnmKpbRh"
      },
      "source": [
        "## 6.1. Train classifiers with base hyper-param settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yex3Efxh2pl5"
      },
      "source": [
        "# train\n",
        "augment_images = False\n",
        "add_batch_normalization = False\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "\n",
        "eval_metrics_CNN_with_DNN = train_model(augment_images, \n",
        "                                        add_batch_normalization, \n",
        "                                        fine_tune_pre_trained_cnn_model)\n",
        "df_eval_metrics_CNN_with_DNN = pd.DataFrame(eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc-lUo7Hkowo"
      },
      "source": [
        "## 6.2. Evaluate classifiers by accuracy of prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2rK82DW5hAs"
      },
      "source": [
        "# Evaluate model results\n",
        "visualize_accuracy_results(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKdDrJZokx2Z"
      },
      "source": [
        "## 6.2. Evaluate classifiers by size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZzhGFXYk6PY"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t-4cW7-k5uq"
      },
      "source": [
        "## 6.3. Evaluate classifers by accuracy vs size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxovO7V3lBtR"
      },
      "source": [
        "# Visualize models by accuracy vs size\n",
        "visualize_accuracy_vs_size(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0yHuZuzlCCW"
      },
      "source": [
        "## 6.4. Evaluate classifers by loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW8yM5ILlFJx"
      },
      "source": [
        "# Visualize models by loss \n",
        "visualize_loss_results(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA3mm9a-lFtM"
      },
      "source": [
        "## 6.5. Evaluate classifiers by AUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GmGNrTylJK_"
      },
      "source": [
        "# Visualize models by AUC\n",
        "visualize_auc_results(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgtGcVGRlJwh"
      },
      "source": [
        "## 6.6. Evaluate classifers by precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fh0kjyjlMVq"
      },
      "source": [
        "# Visualize models by precision\n",
        "visualize_precision_results(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54W-dLCmlMzJ"
      },
      "source": [
        "## 6.7. Evaluate classifers by recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxqZDSmFlRza"
      },
      "source": [
        "# Visualize models by recall\n",
        "visualize_recall_results(df_eval_metrics_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTmDKXFT_drb"
      },
      "source": [
        "# 7.0. Fine tune best CNN + custom layers + DNN classifer hyper parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvPL7bXwkD8O"
      },
      "source": [
        "## 7.1. Fine tune hyper parameters (experiment - 1) num_epochs\n",
        "1. Use baseline hyper-parameters, set num_epochs=25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYKomJhkHG_"
      },
      "source": [
        "# train\n",
        "num_epochs = 20\n",
        "augment_images = False\n",
        "add_batch_normalization = False\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "dropout_rate = 0.2\n",
        "optimizer = 'rmsprop'\n",
        "eval_tuned_metrics_CNN_with_DNN_1 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_1 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSOm2LoDmn-6"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68nI2c5pjmo6"
      },
      "source": [
        "## 7.2. Fine tune hyper parameters (experiment - 2) batch normalization\n",
        "1. Use baseline hyper-parameters, set num_epochs=25\n",
        "2. Add batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDWfiO0xfaQG"
      },
      "source": [
        "# train\n",
        "augment_images = False\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "num_epochs = 20\n",
        "dropout_rate = 0.2\n",
        "optimizer = 'rmsprop'\n",
        "eval_tuned_metrics_CNN_with_DNN_2 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_2 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRKYPkEqo08-"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtXOsWuSo7Gk"
      },
      "source": [
        "## 7.3. Fine tune hyper parameters (experiment - 3) image augmentation\n",
        "1. Use baseline hyper-parameters, set num_epochs=25\n",
        "2. Add batch normalization\n",
        "3. Add image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NudQgBHo2dc"
      },
      "source": [
        "# train\n",
        "augment_images = True\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "num_epochs = 20\n",
        "dropout_rate = 0.2\n",
        "optimizer = 'rmsprop'\n",
        "eval_tuned_metrics_CNN_with_DNN_3 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_3 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XfWfnS8pFK7"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8vIn5mapOit"
      },
      "source": [
        "## 7.4. Fine tune hyper parameters (experiment - 4) dropout_rate\n",
        "1. Use baseline hyper-parameters, set num_epochs=25\n",
        "2. Add batch normalization\n",
        "3. Add image augmentation\n",
        "4. dropout_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zMEpru5pLXd"
      },
      "source": [
        "# train\n",
        "augment_images = True\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "num_epochs = 20\n",
        "dropout_rate = 0.5\n",
        "optimizer = 'rmsprop'\n",
        "eval_tuned_metrics_CNN_with_DNN_4 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_4 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfjqO1WVpMpu"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O09D7kb3plHr"
      },
      "source": [
        "## 7.5. Fine tune hyper parameters (experiment - 5) optimizer\n",
        "1. Use baseline hyper-parameters, set num_epochs=25\n",
        "2. Add batch normalization\n",
        "3. Add image augmentation\n",
        "4. dropout_rate = 0.5\n",
        "5. optimizer =adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTYgiY7qpbu8"
      },
      "source": [
        "# train\n",
        "augment_images = True\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "num_epochs = 20\n",
        "dropout_rate = 0.5\n",
        "optimizer = 'adam'\n",
        "eval_tuned_metrics_CNN_with_DNN_5 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_5 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSmSFTFRphxy"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oja_3V6rwgzm"
      },
      "source": [
        "## 7.6. Fine tune hyper parameters (experiment - 6) unfreeze pre-trained layers\n",
        "1. Use baseline hyper-parameters, set num_epochs=25\n",
        "2. Add batch normalization\n",
        "3. Add image augmentation\n",
        "4. dropout_rate = 0.5\n",
        "5. optimizer=rmsprop\n",
        "6. Unfreeze pre-trained CNN, fine tune last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIX66bSwwc55"
      },
      "source": [
        "# train\n",
        "augment_images = True\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = True\n",
        "num_epochs = 20\n",
        "dropout_rate = 0.5\n",
        "optimizer = 'rmsprop'\n",
        "eval_tuned_metrics_CNN_with_DNN_6 = hyper_param_tune_evaluate_best_DNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_DNN_6 = pd.DataFrame(eval_tuned_metrics_CNN_with_DNN_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7dZQUUHwfuL"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_DNN_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4nFo3JbAbfs"
      },
      "source": [
        "# 8.0. Evaluate best CNN + custom layers + DNN classifer metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-feQyBMB2ME"
      },
      "source": [
        "## 8.1. Evaluate best classifier model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOqLp2VjAcGz"
      },
      "source": [
        "# Visualize best model summary\n",
        "best_model_CNN_with_DNN = visualize_best_model_summary(df_eval_tuned_metrics_CNN_with_DNN_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIz2GpjXCWUJ"
      },
      "source": [
        "## 8.2. Evaluate best classifer classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dpRCJx7B3SE"
      },
      "source": [
        "# Visualize best model classification results\n",
        "visualize_best_model_classification_report(best_model_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDKiCB8WCjUc"
      },
      "source": [
        "## 8.3. Evaluate best classifer confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiLA_tB-B4Ga"
      },
      "source": [
        "# Visualize best model confusion matrix\n",
        "visualize_best_model_confusion_matrix(best_model_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfACQmOkCwhr"
      },
      "source": [
        "## 8.4. Evaluate best classifer top common errors in prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIK0AiARB3i0"
      },
      "source": [
        "# Visualize best model top common errors in prediction\n",
        "visualize_best_model_top_common_errors(best_model_CNN_with_DNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZM9lXiLzkxl"
      },
      "source": [
        "# 9.0.Fine tune best CNN + custom layers + LSTM classifier hyper parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNmBPu66SHEH"
      },
      "source": [
        "## 9.1. Fine tune hyper parameters (experiment - 1) best DNN classifier settings\n",
        "1. num_epochs = 20  \n",
        "2. augment_images  \n",
        "3. add batch normalization layer\n",
        "4. fine tune pre-trained CNN model  \n",
        "5. dropout_rate  = 0.5  \n",
        "6. optimizer = rmsprop  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY2HmVV_-X4r"
      },
      "source": [
        "# train\n",
        "num_epochs = 20\n",
        "augment_images = True\n",
        "add_batch_normalization = True\n",
        "fine_tune_pre_trained_cnn_model = True\n",
        "dropout_rate = 0.5\n",
        "optimizer = 'rmsprop'\n",
        "num_embeddings = 512\n",
        "lstm_units = 64\n",
        "add_dropout = True\n",
        "eval_tuned_metrics_CNN_with_RNN_1 = hyper_param_tune_evaluate_best_RNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 num_embeddings,\n",
        "                                                                                 lstm_units,\n",
        "                                                                                 add_dropout,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_RNN_1 = pd.DataFrame(eval_tuned_metrics_CNN_with_RNN_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDrmlndzj1BQ"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_RNN_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amL0dlEqkI4V"
      },
      "source": [
        "## 9.2. Fine tune hyper parameters (experiment - 2) custom\n",
        "1. Increase lstm units to 512\n",
        "2. Turn off drop out \n",
        "3. Turn off batch normalization\n",
        "4. Turn off fine tuning of pre-trained CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKByHlQ3j8sT"
      },
      "source": [
        "# train\n",
        "num_epochs = 20\n",
        "augment_images = True\n",
        "add_batch_normalization = False\n",
        "fine_tune_pre_trained_cnn_model = False\n",
        "dropout_rate = 0.5\n",
        "optimizer = 'rmsprop'\n",
        "num_embeddings = 512\n",
        "lstm_units = 512\n",
        "add_dropout = False\n",
        "eval_tuned_metrics_CNN_with_RNN_2 = hyper_param_tune_evaluate_best_RNN_classifer(X_train, y_train, X_test, y_test, \n",
        "                                                                                 augment_images,\n",
        "                                                                                 add_batch_normalization,\n",
        "                                                                                 dropout_rate,\n",
        "                                                                                 optimizer,\n",
        "                                                                                 num_epochs,\n",
        "                                                                                 num_embeddings,\n",
        "                                                                                 lstm_units,\n",
        "                                                                                 add_dropout,\n",
        "                                                                                 fine_tune_pre_trained_cnn_model)\n",
        "df_eval_tuned_metrics_CNN_with_RNN_2 = pd.DataFrame(eval_tuned_metrics_CNN_with_RNN_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wOMdYknj-MI"
      },
      "source": [
        "# Visualize models by size\n",
        "visualize_models_by_size(df_eval_tuned_metrics_CNN_with_RNN_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3nWW9gDZuJu"
      },
      "source": [
        "# 10.0. Evaluate best CNN + custom layers + LSTM classifier metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CddKi6cctl_z"
      },
      "source": [
        "## 10.1. Evaluate best classifier model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP5BEKewtpPg"
      },
      "source": [
        "# Visualize best model summary\n",
        "best_model_CNN_with_RNN = visualize_best_model_summary(df_eval_tuned_metrics_CNN_with_RNN_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4cIEOC2tpof"
      },
      "source": [
        "## 10.2. Evaluate best classifier classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arEC2FastvtF"
      },
      "source": [
        "# Visualize best model classification results\n",
        "visualize_best_model_classification_report(best_model_CNN_with_RNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tJxfGUotwAv"
      },
      "source": [
        "## 10.3. Evaluate best classifier confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BveuMi3Itz0p"
      },
      "source": [
        "# Visualize best model confusion matrix\n",
        "visualize_best_model_confusion_matrix(best_model_CNN_with_RNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUOeHzQRt0Kk"
      },
      "source": [
        "## 10.4. Evaluate best classifer top common errors in predicition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRV0g346t5Dn"
      },
      "source": [
        "# Visualize best model top common errors in prediction\n",
        "visualize_best_model_top_common_errors(best_model_CNN_with_RNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urgFD0hMjXQi"
      },
      "source": [
        "# 11.0. Tensorboard integration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySSHdm-SjeOO"
      },
      "source": [
        "# Bring up tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlhGfPqlNWEH"
      },
      "source": [
        "# 12.0. Best Model checkpoint and serve using tensorflow serving\n",
        "\n",
        "The professor provided this [notebook](https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/serving/rest_simple.ipynb) to be used as reference for using tensorflow serving inside google colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSXJQd2VcOhp"
      },
      "source": [
        "## 12.1. Checkpoint and Serve best CNN with DNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN-Ce6z_3Ixe"
      },
      "source": [
        "### 12.1.1. Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs3OQbaEbSmV"
      },
      "source": [
        "best_model = best_model_CNN_with_DNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiLaEPEQavHJ"
      },
      "source": [
        "# Save best model\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "model = best_model\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxbxsTYpa8J5"
      },
      "source": [
        "# Inspect saved model\n",
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0jIexqMdHJp"
      },
      "source": [
        "### 12.1.2. Inspect tensorflow serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4330iFhKOOGX"
      },
      "source": [
        "# Install grpcio\n",
        "!pip install -Uq grpcio==1.32.0\n",
        "print('TensorFlow version: {}'.format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTe-y6baLDPE"
      },
      "source": [
        "# Confirm that we're using Python 3\n",
        "assert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpCYh4eqLEzs"
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "print(\"Installing dependencies for Colab environment\")\n",
        "!pip install -Uq grpcio==1.32.0\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbeuy4WALY6a"
      },
      "source": [
        "# We need sudo prefix if not on a Google Colab.\n",
        "if 'google.colab' not in sys.modules:\n",
        "  SUDO_IF_NEEDED = 'sudo'\n",
        "else:\n",
        "  SUDO_IF_NEEDED = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnR-OIFRLdBz"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | {SUDO_IF_NEEDED} tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | {SUDO_IF_NEEDED} apt-key add -\n",
        "!{SUDO_IF_NEEDED} apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Atkntnw6PdNf"
      },
      "source": [
        "### 12.1.3. Install tensorflow model server if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvg2S2JqMM-j"
      },
      "source": [
        "!{SUDO_IF_NEEDED} apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIhH4EQP8ma"
      },
      "source": [
        "### 12.1.4. Send requests to model using tensorflow serving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYCVLQk-Qs2"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9vQAWLWdiy4"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=breast_cancer_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmmcnA5MQTju"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5L_8Q2eRjuC"
      },
      "source": [
        "test_images=X_test\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:10].tolist()})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtQP0DfnRyl1"
      },
      "source": [
        "### 12.1.5. Make REST requests to server, test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPZCidhSR1dq"
      },
      "source": [
        "!pip install -q requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/breast_cancer_model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "\n",
        "for i in range(len(test_images[1:3])):\n",
        "  print(np.argmax(predictions[i]),y_test[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEdBqbrp6gNf"
      },
      "source": [
        "# 13.0. Archive best model, logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF4E3n8rSUzy"
      },
      "source": [
        "shutil.make_archive('saved_model_tfs', 'zip', MODEL_DIR)\n",
        "shutil.make_archive('logs', 'zip', '/content/logs')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
